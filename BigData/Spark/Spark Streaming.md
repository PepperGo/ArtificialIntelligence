# Spark Streaming
1. Spark Streaming is an extension of the core Spark API that enables scalable, high-throughput, fault-tolerant stream processing of live data streams.   
2. Data can be ingested from many sources like Kafka, Flume, Kinesis, or TCP sockets,   
3. and can be processed using complex algorithms expressed with high-level functions like map, reduce, join and window.   
4. Finally, processed data can be pushed out to filesystems, databases, and live dashboards.  
5. Sparkâ€™s machine learning and graph processing algorithms can be used on data streams.

## Some Example
[Official Examples](https://spark.apache.org/docs/latest/streaming-programming-guide.html#a-quick-example)
- Scala
- Java
- Python

## Reference
1. [Spark Streaming Programming Guide](https://spark.apache.org/docs/latest/streaming-programming-guide.html)
